{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в задании требуется сделать легковесный классификатор, сразу откажемся от идеи использовать нейронные сети, ведь если не требуется state-of-the-art результата даже линейные модели показывают себя неплохо на задачах классификации текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:16:11.071833Z",
     "start_time": "2019-09-26T18:16:11.065727Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:19:30.097915Z",
     "start_time": "2019-09-26T18:19:28.628904Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv').fillna(' ')\n",
    "test = pd.read_csv('./test.csv').fillna(' ')\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обработки текста будем использовать tf-idf на биграммах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:19:16.999456Z",
     "start_time": "2019-09-26T18:18:36.660303Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),\n",
    "                min_df=3, max_df=0.9, strip_accents='unicode',\n",
    "                sublinear_tf=1, token_pattern=r'\\w{1,}', stop_words='english')\n",
    "X = vectorizer.fit_transform(train_text)\n",
    "X_test = vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:03:45.122878Z",
     "start_time": "2019-09-26T18:03:06.318016Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_train_text = vectorizer.fit_transform(train_text)\n",
    "tfidf_test_text = vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный байес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала попробуем решить данную задачу при помощи наивного байеса, который является самой легковесной моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:20:16.657273Z",
     "start_time": "2019-09-26T18:20:16.649895Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_model(clf):\n",
    "    scores = []\n",
    "    for class_name in class_names:\n",
    "        y = train[class_name]\n",
    "        score = np.mean(cross_val_score(clf, X, y, scoring='roc_auc', cv=3))\n",
    "        scores.append(score)\n",
    "    print(\"Total score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:22:59.151899Z",
     "start_time": "2019-09-26T18:22:55.432049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 0.8566646243664794\n"
     ]
    }
   ],
   "source": [
    "bayes_clf = ComplementNB()\n",
    "fit_model(bayes_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы можем видеть даже такая простая модель как наивный байес дает достаточно хорошие результаты, однако стоит попытаться добиться лучшего качества при помощи логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:53:53.730947Z",
     "start_time": "2019-09-26T18:53:53.726200Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(dual=True, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:54:12.998232Z",
     "start_time": "2019-09-26T18:53:54.209582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 0.9794040139355179\n"
     ]
    }
   ],
   "source": [
    "fit_model(lr_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сравнению с предыдущей моделью качество заметно возрасло, однако можно ли повысить его еще больше не особо усложняя модель?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим нашу модель совместив предыдущие две, основываясь на данной статье https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:54:13.005718Z",
     "start_time": "2019-09-26T18:54:13.001135Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "preds = np.zeros((len(test), len(class_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T19:17:47.668447Z",
     "start_time": "2019-09-26T19:17:12.852239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 0.9810456672592762\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "\n",
    "final_model = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    y = train[class_name]\n",
    "    \n",
    "    bayes_clf.fit(X, y)\n",
    "    log_probas = bayes_clf.feature_log_prob_\n",
    "    r = log_probas[-1]/log_probas[0]\n",
    "    X_b = X.multiply(r)\n",
    "    \n",
    "    model = LogisticRegression(dual=True, solver='liblinear')\n",
    "    \n",
    "    score = np.mean(cross_val_score(model, X_b, y, scoring='roc_auc', cv=3))\n",
    "    scores.append(score)\n",
    "    \n",
    "    model.fit(X_b, y)\n",
    "    final_model.append(model)\n",
    "    \n",
    "    submission[class_name] = lr_clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "print(\"Total score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:40:54.610180Z",
     "start_time": "2019-09-26T18:40:54.600165Z"
    }
   },
   "source": [
    "Как можем видеть, качество нашей модели еще немного возрасло, составим теперь посылку на kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T18:56:32.225539Z",
     "start_time": "2019-09-26T18:56:30.899206Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговое качество нашей модели можем видеть здесь:\n",
    "![alt text](score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить данную модель можно при помощи подбора параметра регуляризации у логистической регрессии, а также поигравшись с параметрами tf-idf.\n",
    "\n",
    "Для того чтобы облегчить нашу модель мы можем полностью отказаться от использований фичей из наивного байеса, однако это приводит к падению public score на процент. Также облегчить модель поможет сокращение максимального количества фичей в tf-idf.\n",
    "\n",
    "Баланс между качеством и скоростью выбирается в зависимости от задачи, зачастую нам не нужна идеальная модель, поэтому мы можем сэкономить в ее весе, однако всегда стоит следить за падением качества. Проверить гипотезы о том что же нам лучше, можно на пользователях, например, спрашивая их довольны ли они точностью или скоростью нашего сервиса. Основываясь на данных результатах мы можем понять, какую модель предпочтительнее использовать.\n",
    "\n",
    "Зачастую гораздо рациональнее использовать легкие модели для начального решения задач, а потом уже смотреть устраивает ли нас результат. Разумеется, есть задачи в которых нельзя применить логистическую регрессию, однако даже в них разумно использовать легкие нейронные сети, хотя бы для какого то начального приближения. При этом есть задачи в которых тяжелые модели в разы лучше всех остальных, именно в этих случаях полезно пытаться оптимизировать уже хорошо показавшие себя тяжеловесные модели.\n",
    "\n",
    "Недостатком нашей модели может являться то, что на более серьезных задачах качество наверняка заметно упадет. Поэтому без нейронных сетей обойтись не получится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бонус: Интерпретируемость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, какие слова наша модель считала признаком того, что комментарий является `threat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T19:34:47.975093Z",
     "start_time": "2019-09-26T19:34:47.971984Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T19:42:08.339615Z",
     "start_time": "2019-09-26T19:42:08.174566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kill',\n",
       " 'die',\n",
       " 'fucking',\n",
       " 'death',\n",
       " 'rape',\n",
       " 'ass',\n",
       " 'going',\n",
       " 'burn',\n",
       " 'fuck',\n",
       " 'shoot',\n",
       " 'destroy',\n",
       " 'hope die',\n",
       " 'dead',\n",
       " 'hope',\n",
       " 'hang']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_word = {vocab[word]:word for word in vocab}\n",
    "inds = final_model[3].coef_.squeeze().argsort()[-15:][::-1]\n",
    "words = [idx_to_word[ind] for ind in inds]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это было просто, ведь логистическая регрессия очень хорошо интерпретируется. Те слова, которым присвоены наибольшие веса и влияют на итоговый вердикт нашей модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
